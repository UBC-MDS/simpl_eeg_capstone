{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5a995a",
   "metadata": {},
   "source": [
    "# Clustering using Hidden Markov Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3527e4a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpl_eeg import raw_voltage, eeg_objects, connectivity, topomap_2d, topomap_3d_brain, topomap_3d_head\n",
    "from hmmlearn import hmm\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d150736",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b50fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_full = mne.io.read_raw_eeglab('../../data/927/fixica.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccad9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_df = raw_full.to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f17b4",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get average chunked data\n",
    "\n",
    "cleaned_df = entire_df[(entire_df.T != 0).any()] # drop rows where all values are zero\n",
    "\n",
    "sliced_df = entire_df.iloc[:5540000]\n",
    "avg_chunked_list = []\n",
    "for i in range(554):\n",
    "    avg_sliced_array = sliced_df.iloc[i*10000:i*10000+10000, 1:].mean().to_numpy() # separate the data into chunks of per 5 seconds and get the average\n",
    "    avg_chunked_list.append(avg_sliced_array)\n",
    "avg_chunked_array=np.array(avg_chunked_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b33279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get chunk data, not used since file is too large and the operation runs out of memory\n",
    "\n",
    "# avg_df = entire_df.groupby(\"time\").mean().reset_index()\n",
    "# entire_list = []\n",
    "# for i in range(541):\n",
    "#     sliced_array = avg_df.iloc[i*10000:i*10000+10000, 1:].to_numpy().reshape(-1)\n",
    "#     entire_list.append(sliced_array)\n",
    "# entire_array_chunk = np.array(entire_list)\n",
    "\n",
    "# entire_array_chunk=np.float32(entire_array_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ead7ff",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_comp = {}\n",
    "model_list = []\n",
    "for n_comp in range(1, 101, 1):\n",
    "    model = hmm.GaussianHMM(n_components=n_comp)\n",
    "    model_list.append(model)\n",
    "    model.fit(avg_chunked_array)\n",
    "    result = model.decode(avg_chunked_array, algorithm=\"viterbi\")\n",
    "    tune_comp[n_comp] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483deea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = max(tune_comp, key=tune_comp.get) \n",
    "print(f\"The best # of cluster is {maximum}, with log probability of {tune_comp[maximum]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668d132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
