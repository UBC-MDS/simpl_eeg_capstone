{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95e70ca",
   "metadata": {},
   "source": [
    "# 3D Brain Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a8f4d",
   "metadata": {},
   "source": [
    "## Topographic map in 3D brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80fae7",
   "metadata": {},
   "source": [
    "![](instruction_imgs/topomap_3d_brain.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc5e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpl_eeg import eeg_objects, topomap_3d_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfba11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f04c9a",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Please include the line below in your IDE so that the changes would be simultaneously reflected when you make a change to the python scripts.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed6f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9541ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf42afa",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef698db",
   "metadata": {},
   "source": [
    "### Define global parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc23625",
   "metadata": {},
   "source": [
    "There are some common parameters for all functions in this package, it would be more convenient to define all parameters before going into each functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7159314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values belo to values of interest\n",
    "\n",
    "experiment = \"../../data/927\" # path to the experiment folder.\n",
    "nth_epoch = 0\n",
    "colormap = \"RdBu_r\" # select from [\"RdBu_r\", \"hot\", \"cool\", \"inferno\", \"turbo\", \"rainbow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939391b7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e23b7",
   "metadata": {},
   "source": [
    "### Create epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999ae2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/sasha/mds/simpl_eeg_capstone/data/927/fixica.fdt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 matching events found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 33 events and 2049 original time points ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "tmin = -0.3  # number of seconds before the impact. Please change it to a value of your interest\n",
    "tmax = 0.7  # number of seconds after the impact. Please change it to a value of your interest\n",
    "start_second = None  # starting time of the epoch. Please change it to a value of your interest\n",
    "\n",
    "raw = eeg_objects.Epochs(experiment, tmin, tmax, start_second)\n",
    "\n",
    "raw.set_nth_epoch(nth_epoch)\n",
    "\n",
    "epoch = raw.get_nth_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4f7d1",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56e6e3",
   "metadata": {},
   "source": [
    "### Create the topographic map in 3D brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7a100",
   "metadata": {},
   "source": [
    "```{note}\n",
    "- Before an animation or plot can be generated a **\"forward\"** and **\"inverse\"** (abbreviated as **\"stc\"**) must first be generated. If they are not provided to either of the plotting animations they will be automatically generated **HOWEVER** this will increase the time it takes to generate the figure.\n",
    "\n",
    "- The forward/inverse are used to retrieve a brain model to attach the EEG data to and to do some of the mapping calculations. The forward downloads 'fsaverage' MRI data which represents a brain averaged out from dozens of different patients.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397cd61a",
   "metadata": {},
   "source": [
    "#### Generate Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0a20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from root.txt in /Users/sasha/mne_data/MNE-fsaverage-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from bem.txt in /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI -> head transform : /opt/miniconda3/lib/python3.8/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement data      : instance of Info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conductor model   : /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate field computations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do computations in head coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free source orientations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2 source spaces a total of 20484 active source locations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate transformation: MRI (surface RAS) -> head\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.999994  0.003552  0.000202      -1.76 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -0.003558  0.998389  0.056626      31.09 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -0.000001 -0.056626  0.998395      39.60 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.000000  0.000000  0.000000       1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read  19 EEG channels from info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head coordinate coil definitions created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source spaces are now in head coordinates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the BEM model using /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading surfaces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the solution matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three-layer model surfaces loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded linear_collocation BEM solution from /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employing the head->MRI coordinate transform with the BEM model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEM model fsaverage-5120-5120-5120-bem-sol.fif is now set up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source spaces are in head coordinates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping interior check for 2433 sources that fit inside a sphere of radius   47.7 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping solid angle check for 0 points using Qhull\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping interior check for 2241 sources that fit inside a sphere of radius   47.7 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping solid angle check for 0 points using Qhull\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up for EEG...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing EEG at 20484 source locations (free orientations)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "fwd = topomap_3d_brain.create_fsaverage_forward(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8977c",
   "metadata": {},
   "source": [
    "#### Generate Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76876e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using tolerance 1.8e-11 (2.2e-16 eps * 19 dim * 4.3e+03  max singular value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Estimated rank (eeg): 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEG: rank 19 computed from 19 data channels with 0 projectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data rank from 19 -> 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating covariance using EMPIRICAL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating covariance using SHRUNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-validation to select the best estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used : 2049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -66.294\n",
      "   empirical: -187.228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting best estimator: shrunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting forward solution to surface orientation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Converting to surface-based source orientations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 19 channels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19 out of 19 channels remain after picking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 19 channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the depth weighting matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19 EEG channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    limit = 20485/20484 = 9.583809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    scale = 9.50316e+09 exp = 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying loose dipole orientations to surface source spaces: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitening the forward solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from covariance with rank=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using tolerance 3.7e-13 (2.2e-16 eps * 19 dim * 88  max singular value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Estimated rank (eeg): 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEG: rank 19 computed from 19 data channels with 0 projectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Setting small EEG eigenvalues to zero (without PCA)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the source covariance matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting source covariance matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 2.66383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    scaling factor to adjust the trace = 3.61722e+24 (nchan = 19 nzero = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Created the regularized inverter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    The projection vectors do not apply to these channels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Created the whitener using a noise covariance matrix with rank 19 (0 small eigenvalues omitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computing noise-normalization factors (dSPM)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked 19 channels from the data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Eigenleads need to be weighted ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 1 / 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    }
   ],
   "source": [
    "stc = topomap_3d_brain.create_inverse_solution(epoch, fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b6c1f",
   "metadata": {},
   "source": [
    "#### Generate figure with pyvista backend (NOT CURRENTLY WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e3402c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyvista_brain_fig = topomap_3d_brain.plot_topomap_3d_brain(epoch, stc = stc, backend = 'pyvista')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea854c0",
   "metadata": {},
   "source": [
    "#### Save animation with pyvista backend (NOT CURRENTLY WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79415fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topomap_3d_brain.save_animated_topomap_3d_brain(pyvista_brain_fig, filename = \"brain_animation.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05772a36",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9594a1",
   "metadata": {},
   "source": [
    "#### Generate figure with matplotlib backend (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd2dcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "matplot_brain_fig = topomap_3d_brain.plot_topomap_3d_brain(epoch, stc = stc, backend = 'matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626f61d",
   "metadata": {},
   "source": [
    "##### Save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8364d260",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exports/topomap_3d_brain.svg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-54c6db6a71d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"exports/topomap_3d_brain.svg\"\u001b[0m  \u001b[0;31m# change the file path to where you would like to save the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmatplot_brain_fig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3003\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36mprint_svg\u001b[0;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0m__\u001b[0m \u001b[0mDC_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \"\"\"\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage path-likes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exports/topomap_3d_brain.svg'"
     ]
    }
   ],
   "source": [
    "# You could change the plot to different formats by changing the format argument in the function. \n",
    "# It supports 'png', 'pdf', 'svg'.\n",
    "\n",
    "file_path = \"exports/topomap_3d_brain.svg\"  # change the file path to where you would like to save the file\n",
    "\n",
    "matplot_brain_fig.savefig(file_path, format= 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddcddd",
   "metadata": {},
   "source": [
    "#### Generate animation with matplotlib backend (slow but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "matplotlib_animation = topomap_3d_brain.animate_matplot_brain(epoch, stc = stc, views = 'lat', hemi = 'lh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac9e16",
   "metadata": {},
   "source": [
    "##### Save the animation as gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cab2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "anim_brain = topomap_3d_brain.animate_matplot_brain(epoch, stc = stc, views = 'lat', hemi = 'lh')\n",
    "\n",
    "# use a writer if you want to specify frames per second\n",
    "from matplotlib.animation import PillowWriter\n",
    "\n",
    "writer = PillowWriter(fps=5)\n",
    "\n",
    "gif_file_path = \"exports/topomap_3d_brain.gif\"  # change the file path to where you would like to save the file\n",
    "anim_brain.save(gif_file_path, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e94e12",
   "metadata": {},
   "source": [
    "#### Save the animation as mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecf8f5",
   "metadata": {},
   "source": [
    "```{note}\n",
    "You would need to save it as gif file first and then convert it into mp4 file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "\n",
    "clip = mp.VideoFileClip(\"exports/topomap_3d_brain.gif\") # change the file path to where you saved the gif file\n",
    "clip.write_videofile(\"exports/topomap_3d_brain.mp4\")  # change the file path to where you would like to save the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67bf43",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}