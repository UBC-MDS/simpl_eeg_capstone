{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Brain Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topographic map in 3D brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](instruction_imgs/topomap_3d_brain.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpl_eeg import eeg_objects, topomap_3d_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Please include the line below in your IDE so that the changes would be simultaneously reflected when you make a change to the python scripts.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A detailed description of all parameters can be found in the `topomap_2d.animate_topomap_2d` docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function animate_matplot_brain in module simpl_eeg.topomap_3d_brain:\n",
      "\n",
      "animate_matplot_brain(epoch, stc='auto', views=['lat', 'dor', 'fro'], size=200, hemi='both', colormap='mne', colorbar=True, colormap_limit_type='lims', cmin=None, cmid=None, cmax=None, spacing='oct5', smoothing_steps=2, timestamp=True, frame_rate=12, **kwargs)\n",
      "    Creates an animated view of all timestamp observations an mne.epochs.Epochs data using a matplotlib backend.\n",
      "    If multiple views are used then speed becomes significantly slower. Colorbar placement may be inconsistent.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    epoch : mne.epochs.Epochs or mne.evoked.EvokedArray\n",
      "            MNE epochs or evoked object containing portions of raw EEG data built around specified\n",
      "            timestamp(s) The inverse solution will be built based on the data in the specified epoch.\n",
      "    \n",
      "    stc: mne.source_estimate.SourceEstimate or 'auto'\n",
      "            'inverse_solution' to generate the plot from. If set to \"auto\" (default) then an stc will be\n",
      "            automatically generated however, this will significantly increase running time.\n",
      "    \n",
      "    views: str or list\n",
      "            Specifies the 'view' parameter in the mne.SourceEstimate.plot() function. For any backend\n",
      "            can be any combination of 'lat' (lateral), 'med' (medial), 'ros' (rostral), 'cau' (caudal),\n",
      "            'dor' (dorsal), 'ven'(ventral), 'fro'(frontal), 'par' (parietal). The following arguments\n",
      "            are also accepted but are NOT compatible with the matplotlib backend 'axi' (axial), 'sag'\n",
      "            (sagittal), and 'cor'(coronal). Defaults to ['lat', 'fro', 'dor'].\n",
      "    \n",
      "    size: int\n",
      "            If using a non-matplotlib backend then specifies how many pixels tall EACH \"view\" of the brian will be.\n",
      "            If using matplotlib as a backend then the height will be divided by 100 and rounded the closest inch.\n",
      "            For example, entering 100 will result in 1 inch per view. If plotting multiple views overall size of\n",
      "            the multiplot is automatically calculated to fit all views. Defaults to 300.              \n",
      "    \n",
      "    hemi: 'lh’ or ‘rh’ or ‘both’ or ‘split’\n",
      "            Specifies the 'initial_time' parameter in the mne.SourceEstimate.plot() function. Can be\n",
      "            one of ‘lh’, ‘rh’, ‘both’, or ‘split’. Defaults to 'both'. Note that when using the matplotlib\n",
      "            backend that 'split' and 'both' will return a 'split' view since both is not avalible.\n",
      "            Defaults to 'both'\n",
      "    \n",
      "    colormap: str or np.ndarray of float, shape(n_colors, 3 | 4)\n",
      "            Specifies the 'colormap' parameter in the mne.SourceEstimate.plot() function. Can use a\n",
      "            matplotlib colormap by name or take a custom look up table as input. Defaults to \"mne\"\n",
      "    \n",
      "    colorbar: bool\n",
      "            Determines whether to include a colorbar on the plot not. Defaults to True.\n",
      "    \n",
      "    colormap_limit_type: str\n",
      "            Can be either \"lims\" or \"pos_lims\". \"lims\" means that your cmin, cmid, and cmax values will specify the\n",
      "            \"Lower, middle, and upper bounds for colormap\". Using \"pos_lims\" will lead to cmin, cmid, and cmax representing\n",
      "            the \"Lower, middle, and upper bound for colormap. Positive values will be mirrored directly across\n",
      "            zero during colormap construction to obtain negative control points.\" Defaults to \"lims\"\n",
      "    \n",
      "    cmin: float\n",
      "            Specifies the lower value of the colormap limit. If no value is specified then\n",
      "            limits will be automatically calculated based on the mne.SourceEstimate.plot() function defaults OR\n",
      "            will be the negative value of cmax if only that is provided.\n",
      "    \n",
      "    cmid: float\n",
      "            Specifies the middle value of the colormap limit. If no value is specified then\n",
      "            limits will be automatically calculated based on the mne.SourceEstimate.plot() function defaults OR\n",
      "            will be the value between cmin and cmax if one/both of them is provided.\n",
      "    \n",
      "    cmax: float\n",
      "            Specifies the middle value of the colormap limit. If no value is specified then\n",
      "            limits will be automatically calculated based on the mne.SourceEstimate.plot() function defaults OR\n",
      "            will be the negative value of cmin if only that is provided.\n",
      "    \n",
      "    spacing: str\n",
      "            Specifies the 'spacing' parameter in the mne.SourceEstimate.plot() function. \"The spacing to use for the\n",
      "            source space. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided\n",
      "            octahedron. In general, you can speed up the plotting by selecting a sparser source\n",
      "            space. Has no effect with mayavi backend. Defaults to ‘oct6’\".\n",
      "    \n",
      "    smoothing_steps: int\n",
      "            Specifies the 'smoothing_steps' parameter in the mne.SourceEstimate.plot() function. \"The amount of smoothing\".\n",
      "            3 by default.\n",
      "            \n",
      "    timestamp: 'auto' or bool\n",
      "        Specifies whether or not to show the timestamp on the plot relative to the time in the epoch that\n",
      "        is being shown. Only works with 'matplotlib' set to the backend. Defaults to 'auto' which be True\n",
      "        if a matplotlib backend is being used and False otherwise.\n",
      "            \n",
      "    frame_rate: int\n",
      "            The frame rate to render the animation at. Defautls to 12.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ani: matplotlib.animation.FuncAnimation\n",
      "            Animation containing frames from all of the avalible times in the passed in epoch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(topomap_3d_brain.animate_matplot_brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values belo to values of interest\n",
    "\n",
    "experiment_folder = \"../../data/109\"  # path to the experiment folder\n",
    "nth_epoch = 0  # the epoch of interest\n",
    "\n",
    "# 3D brain parameters\n",
    "colormap = \"RdBu_r\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create epoched data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For additional options see **Creating EEG Objects** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/sasha/mds/simpl_eeg_capstone/data/109/fixica.fdt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 matching events found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 33 events and 2049 original time points ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs = eeg_objects.Epochs(experiment_folder)\n",
    "epoch = epochs.get_nth_epoch(nth_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the topographic map in 3D brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "- Before an animation or plot can be generated a **\"forward\"** and **\"inverse\"** (abbreviated as **\"stc\"**) must first be generated. If they are not provided to either of the plotting animations they will be automatically generated **HOWEVER** this will increase the time it takes to generate the figure.\n",
    "\n",
    "- The forward/inverse are used to retrieve a brain model to attach the EEG data to and to do some of the mapping calculations. The forward downloads 'fsaverage' MRI data which represents a brain averaged out from dozens of different patients.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from root.txt in /Users/sasha/mne_data/MNE-fsaverage-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from bem.txt in /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI -> head transform : /opt/miniconda3/lib/python3.8/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement data      : instance of Info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conductor model   : /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate field computations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do computations in head coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free source orientations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2 source spaces a total of 20484 active source locations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate transformation: MRI (surface RAS) -> head\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.999994  0.003552  0.000202      -1.76 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -0.003558  0.998389  0.056626      31.09 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -0.000001 -0.056626  0.998395      39.60 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.000000  0.000000  0.000000       1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read  19 EEG channels from info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head coordinate coil definitions created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source spaces are now in head coordinates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the BEM model using /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading surfaces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the solution matrix...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three-layer model surfaces loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded linear_collocation BEM solution from /Users/sasha/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employing the head->MRI coordinate transform with the BEM model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEM model fsaverage-5120-5120-5120-bem-sol.fif is now set up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source spaces are in head coordinates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping interior check for 2433 sources that fit inside a sphere of radius   47.7 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping solid angle check for 0 points using Qhull\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping interior check for 2241 sources that fit inside a sphere of radius   47.7 mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skipping solid angle check for 0 points using Qhull\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up for EEG...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing EEG at 20484 source locations (free orientations)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "fwd = topomap_3d_brain.create_fsaverage_forward(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using tolerance 2e-11 (2.2e-16 eps * 19 dim * 4.7e+03  max singular value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Estimated rank (eeg): 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEG: rank 19 computed from 19 data channels with 0 projectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data rank from 19 -> 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating covariance using EMPIRICAL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating covariance using SHRUNK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-validation to select the best estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used : 2049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -48.219\n",
      "   empirical: -155.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting best estimator: shrunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting forward solution to surface orientation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Converting to surface-based source orientations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 19 channels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19 out of 19 channels remain after picking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 19 channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the depth weighting matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19 EEG channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    limit = 20485/20484 = 9.583809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    scale = 9.50316e+09 exp = 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying loose dipole orientations to surface source spaces: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitening the forward solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from covariance with rank=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using tolerance 4.5e-13 (2.2e-16 eps * 19 dim * 1.1e+02  max singular value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Estimated rank (eeg): 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEG: rank 19 computed from 19 data channels with 0 projectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Setting small EEG eigenvalues to zero (without PCA)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the source covariance matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting source covariance matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 2.79772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    scaling factor to adjust the trace = 4.25971e+26 (nchan = 19 nzero = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Created the regularized inverter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    The projection vectors do not apply to these channels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Created the whitener using a noise covariance matrix with rank 19 (0 small eigenvalues omitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computing noise-normalization factors (dSPM)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked 19 channels from the data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Eigenleads need to be weighted ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 1 / 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    }
   ],
   "source": [
    "stc = topomap_3d_brain.create_inverse_solution(epoch, fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate figure with pyvista backend (NOT CURRENTLY WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyvista_brain_fig = topomap_3d_brain.plot_topomap_3d_brain(epoch, stc = stc, backend = 'pyvista')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save animation with pyvista backend (NOT CURRENTLY WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topomap_3d_brain.save_animated_topomap_3d_brain(pyvista_brain_fig, filename = \"brain_animation.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate figure with matplotlib backend (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "matplot_brain_fig = topomap_3d_brain.plot_topomap_3d_brain(epoch, stc = stc, backend = 'matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could change the plot to different formats by changing the format argument in the function. \n",
    "# It supports 'png', 'pdf', 'svg'.\n",
    "\n",
    "file_path = \"../../exports/examples/topomap_3d_brain.svg\"  # change the file path to where you would like to save the file\n",
    "\n",
    "matplot_brain_fig.savefig(file_path, format= 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate animation with matplotlib backend (slow but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "matplotlib_animation = topomap_3d_brain.animate_matplot_brain(epoch, stc = stc, views = 'lat', hemi = 'lh')\n",
    "\n",
    "from IPython.display import HTML\n",
    "video = HTML(matplotlib_animation.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "anim_brain = topomap_3d_brain.animate_matplot_brain(epoch, stc = stc, views = 'lat', hemi = 'lh')\n",
    "\n",
    "gif_file_path = \"../../exports/examples/topomap_3d_brain.gif\"  # change the file path to where you would like to save the file\n",
    "anim_brain.save(gif_file_path, fps=5, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "mp4_file_path = \"../../exports/examples/topo_2d.mp4\"  # change the file path to where you would like to save the file\n",
    "anim_brain.save(mp4_file_path, fps=5, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "If `FFMpegWriter` does not work on your computer you can save the file as a gif first and then convert it into mp4 file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "\n",
    "clip = mp.VideoFileClip(gif_file_path) # change the file path to where you saved the gif file\n",
    "clip.write_videofile(mp4_file_path)  # change the file path to where you would like to save the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}